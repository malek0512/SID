---
title: "partie1"
output: html_document
---

** Database normalisation**

```{r}
# Utils
splitIn <- function(percentage = 0.75, df){
  nb_rows <- length(df$Y)
  percent = floor(percentage * nb_rows)
  
  df$Ys <- list("1"=df$Y[1:percent], "2"=df$Y[(percent+1):nb_rows])
  df$Xs <- list("1"=df$X[1:percent,], "2"=df$X[(percent+1):nb_rows,])
  
  return (df)
}
  
Swap <- function(df) {
  columns <- names(df)
  columns <- columns[1:(length(columns)-1)]
  
  return (list(X=data.matrix(df[, columns]), Y=as.vector(df[, length(df)])))
}

SwapInv <- function(df) {
  df <- data.frame(cbind(df$Y, df$X))
  
  return (list(X=data.matrix(df[, columns]), Y=as.vector(df[, length(df)])))
}

getDataBase <- function(database) {
  #filepath = "/home/eudes/ricm5-1/sid/projet/SID"
  #filepath = "/media/mammar/5766C1AE34748499/work/SID/TP-Perceptron"
  filepath = "."
  if (database == "breast.cancer")
  {
    # **Pre treatment for breast.cancer.wisconsin.data database**
    # On remplace 2 (bénigne) par +1 et 4 (maligne) par -1
    filename = "breast-cancer-wisconsin.data.txt"
    
    breast.cancer.wisconsin.data <-read.table(paste(filepath, filename, sep = "/"), sep = ",")
    df <- breast.cancer.wisconsin.data
    df = subset(df, V7!="?")          # on vire les ligne contenant des "?"
    df$V7 <- as.numeric(df$V7)        # on reconvertie en numeric
    df = subset(df, select = -c(V1))  # on vire la colonne 1
    
    df$V11 <- as.character(df$V11)    # transforme la derniere colone par 1 et -1
    df$V11[df$V11 == "2"] <- "1"
    df$V11[df$V11 == "4"] <- "-1"
    df$V11 <- as.numeric(df$V11)      # on reconvertie en numeric
    
    # on normalise les descripteurs en divisant par leur max
    for(column in names(df))
    {
      df[column] <- df[column] / max(df[column])
    }
    
    return (Swap(df))  
  } else if (database == "ionosphere")
  {
    #**Pre treatment for ionosphere.data database**
    #Le fichier est deja normalisé, on remplace b (bad) par -1, et g (good) par +1
    filename = "ionosphere.data.txt"
    ionosphere <-read.table(paste(filepath, filename, sep = "/"), sep = ",")
    
    df <-ionosphere
    df$V35 <- as.character(df$V35)      # transforme la derniere colone par 1 et -1
    df$V35[df$V35 == "b"] <- "-1"
    df$V35[df$V35 == "g"] <- "1" 
    df$V35 <- as.numeric(df$V35)      # on reconvertie en numeric
    
    return (Swap(df))  
  } else if (database == "spambase")
  {
    #**Pre treatment for spambase.data database**
    #On remplace 1 (c'est un spam) par +1 et 0 (non un spam) par +1
    filename = "spambase.data.txt"
    
    spambase <-read.table(paste(filepath, filename, sep = "/"), sep = ",")
    df <-spambase
    df$V58 <- as.character(df$V58)      # transforme la derniere colone par 1 et -1
    df$V58[df$V58 == "1"] <- "-1"
    df$V58[df$V58 == "0"] <- "1"
    df$V58 <- as.numeric(df$V58)
    
    # on normalise les descripteurs en divisant par leur max
    for(column in names(df))
    {
      df[column] <- df[column] / max(df[column])
    }
    
    return (Swap(df))  
  }
}

#getDataBase(database = "breast.cancer")
```

**Models algorithms**
```{r}
perceptron <- function(T = 5000, eta = 0.1, X, Y) {
  m <- nrow(X)
  d <- ncol(X)
  # Initialisation of the weight vector
  w0 <- 0
  w <- array(data = 0, dim = d,dimnames = NULL)
  t <- 0
  
  # While the maximum number of iterations is not reached do 
  while (t <= T)
  {
    row <- round(runif(1, 1, m))
    x <- X[row,]
    y <- Y[row]
    ps <- x %*% w
    if ( y * ( ps + w0 ) <= 0 )
    {
      w0 <- w0 + eta * y
      w <- w + eta * y * x
    }
    t <- t + 1
  }
  
  return (list(w0=w0, w=w))
}

adaline <- function(T = 5000, eta = 0.1, X, Y) {
  m <- nrow(X)
  d <- ncol(X)
  # Initialisation of the weight vector
  w0 <- 0
  w <- array(data = 0, dim = d,dimnames = NULL)
  t <- 0
  
  # While the maximum number of iterations is not reached do 
  while (t <= T)
  {
    row <- round(runif(1, 1, m))
    x <- X[row,]
    y <- Y[row]
    
    hw <- (x %*% w + w0)[1,1]
    
    w0 <- w0 + eta * (y - hw)
    w <- w + eta * x * (y - hw)
    
    t <- t + 1
  }
  
  return (list(w0=w0, w=w))
}

Logistique_prof <- function(T = "fake_parameter", eta = "fake_parameter", precision=1e-4, X, Y) {
  filename = "logistic-data"
  resultname = "logistic-result"
  filepath = "."
  
  executable = "./LogisticRegression/LogisticRegression-learn"
  params = paste("-e", precision, sep = " ")
  
  #writeToDisk
  df <- data.frame(cbind(Y, X))
  write.table(df, file = paste(filepath, filename, sep = "/"), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = " ")
  
  #execution
  cmd=paste(executable, params, filename,  resultname, sep=' ')
  system(cmd, ignore.stdout = TRUE)
  
  #reading the result
  data <- read.table(paste(filepath, resultname, sep = "/"), sep = " ")
  #data[!is.na(data)]
  
  w0 <- data[1]
  w <- data[c(-1, -ncol(data))]  
  
  return (list(w=data.matrix(w)[1,], w0=w0[1,1]))
}

regression_logistique <- function(T = 5000, eta = 1.0, precision = 0.1, X, Y) {
  Hw <- function(X, w, w0) {return (X %*% w + w0) }
  Rm <- function(X, Y, w, w0) { return (mean(log2( 1 + exp( -Y * Hw(X, w, w0)))))}
  Gradient <- function(X, Y, w, w0) {
    d <- ncol(X)
    grad = c()
    #Hw <- function(x, w, w0) {return (x %*% w + w0) }
    for(j in 1:d)
    {
      grad[j] <- mean(-Y*X[,j]*(1-(1/(1+exp(-Y * Hw(X = X, w = w, w0 = w0))))))
    }
    
    return (grad)
  }

  m <- nrow(X)
  d <- ncol(X)
  # Initialisation of the weight vector
  w0 <- 0
  #w <- array(data = 0, dim = d,dimnames = NULL)
  w <- runif(n = d, min = 0, max = d)
  t <- 0
  Rold <- 1
  Rnew <- 0
  
  # While the maximum number of iterations is not reached do 
  while ( abs( Rnew - Rold ) > precision )
  {
    Rold <- Rm(X = X, Y = Y, w = w, w0 = w0)
    
    gradient <- Gradient(X, Y, w, w0)

    w <- w - eta * gradient
    w0 <- w0 - eta * mean(-Y*(1-(1/(1+exp(-Y * Hw(X = X, w = w, w0 = w0))))))
    
    Rnew <- Rm(X = X, Y = Y, w = w, w0 = w0)
      
    t <- t + 1
    
  }
  
  return (list(w0=w0, w=w))
}

Adaboost_prof <- function(T = "fake_parameter", eta = 0.1, max_iterations = 100, X, Y) {
  
  filename = "adaboost-data"
  resultname = "adaboost-result"
  filepath = "."
  
  executable = "./AdaBoost/AdaBoost-learn"
  params = paste("-e", eta, "-t", max_iterations, sep = " ")
  
  #writeToDisk
  df <- data.frame(cbind(Y, X))
  write.table(df, file = paste(filepath, filename, sep = "/"), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = " ")
  
  #execution
  cmd=paste(executable, params, filename,  resultname, sep=' ')
  system(cmd, ignore.stdout = TRUE)
  
  #reading the result
  data <- read.table(paste(filepath, resultname, sep = "/"), sep = " ")
  data <- data[, 1:(ncol(data)-1)]
  
  #on a une liste de vecteurs sous la forme : alpha, w0, w ...
  #on multiple chaque w0(i) et w(i) par le alpha(i), et on somme les w0 = sum(w0(i)) et w = sum(w(i))
  data <- data[,1] * data[,2:ncol(data)]
  data <- colSums(data)
  
  
  return (list(w0 = data[1], w=data[-1]))
}
```


```{r}
model_test <- function(X, Y, w, w0){
  h <- w0 + X %*% w
  #m <- nrow(X)
  m <- length(Y)

  PosPred=PosEffect=PosEffPred=Erreur=0.0
  for(i in 1:m){
    
    if(Y[i]*h[i] <= 0.0)
      Erreur <- Erreur + 1.0
    if(Y[i]==1.0){
      PosEffect <- PosEffect + 1.0
      if(h[i] > 0.0)
        PosEffPred <- PosEffPred + 1.0
    }
    if(h[i] > 0.0)
      PosPred <- PosPred + 1.0
    
  }
    
  Erreur <- Erreur / m
  Precision <- PosEffPred / PosPred
  Rappel <- PosEffPred / PosEffect
  F <- 2.0 * Precision * Rappel / ( Precision + Rappel )
  
  return (list(erreur=Erreur, precision = Precision, rappel= Rappel, f=F, h=h))
}

#perceptron_test(df = learn)
```


**Estimation du pas d'apprentissage, par validation croisée**

```{r}
# we set a seed for the random generator
set.seed(10);

evaluate_model <- function (df = NULL, model = perceptron, model_test = model_test) {
  # constantes
  etas <- c(10^-5, 10^-4, 10^-3, 10^-2, 10^-1)
  model_loop = 5000

  # creating St and Tt databases
  dftmp <- splitIn(percentage = 0.75, df = df)
  St <- list(X = dftmp$Xs$"1", Y = dftmp$Ys$"1")
  Tt <- list(X = dftmp$Xs$"2", Y = dftmp$Ys$"2")
  
  # variables for model evaluation
  X <- St$X
  Y <- St$Y
  m <- nrow(X)
  sequence <- seq(from = 1, to = m)
  percent <- floor((1/5) * m)
  error_estimations = c()
  #result <- list()
  #result2 <- list()
  for(t in 1:20)
  {
    # looking for the best eta
    errors<- c()
    for(eta in etas)
    {
      if (identical(model, Logistique_prof)) #
      {
        errors = etas
        break;
      }
      
      estimations <- c()
      # cross validation pour un eta donné
      for(i in 1:5)
      {
        # on tire aleatoirement 1/5  des indices sans remise
        indexes <- sample(sequence, size = percent,replace = FALSE)
        complementaire <- sequence[-indexes]
        learn_4_5_X <- X[complementaire,]
        learn_4_5_Y <- Y[complementaire]
        
        test_1_5_X <- X[indexes,]
        test_1_5_Y <- Y[indexes]
        
        equation <- model(T = model_loop, eta = eta, X = learn_4_5_X, Y = learn_4_5_Y)
        estimations[i] <- model_test(X = test_1_5_X, Y = test_1_5_Y, w = equation$w, w0 = equation$w0)$erreur
      }
      #result <- rbind(result, data.frame(iter=t, eta=eta, error_mean=mean(estimations)))
      errors <- c(errors, mean(estimations))
    }
    best_eta <- etas[which.min(errors)]
    
    ############################################
    #apprentissage du model a partir de best_eta
    equation <- model(T = model_loop, eta = best_eta, X = St$X, Y = St$Y)
    test_result <- model_test(X = Tt$X, Y = Tt$Y, w = equation$w, w0 = equation$w0)
    
    #result2 = rbind(result2, data.frame(iter = t, equation$w[1], best_eta = best_eta, test_result$h, Tt$Y, test_result$erreur))
    #error_estimations[t] <- model_test(X = Tt$X, Y = Tt$Y, equation$w,equation$w0)$erreur
    error_estimations[t] <- test_result$erreur
  }
  
  mean_error_estimation = mean(error_estimations)
  return (list(eta = best_eta, mean_error_estimation = mean_error_estimation)) #, df = result2
}

#evaluate_model(df = getDataBase(database = "breast.cancer"), model = perceptron, model_test = model_test)

```

Nous allons à présent comparer les performances des modèles Adaline et Perceptron sur les 3 bases de données UCI (préalablement normalisées) : 

```{r}


uci = c("breast.cancer", "ionosphere", "spambase")
models = c("perceptron", "adaline", "regression_logistique", "Adaboost_prof")
#models = c("Adaboost_prof", "Logistique_prof")
#models = c("regression_logistique")
#models = c("perceptron")
#models = c("Adaboost_prof")
data = data.frame()
for(model in models) 
{
  set.seed(42)
  for(database in uci)
  {
    print(model)
    res = evaluate_model(df = getDataBase(database = database), model = get(model), model_test = model_test)
    data = rbind(data, data.frame(model, database, eta=res$eta, error = res$mean_error_estimation))
  }  
}

data

ggplot(data, aes(model, error, fill=model)) + geom_bar(stat = "identity") + facet_grid(. ~ database)
```

```{r}
library("plyr")
res = data.frame()
for(database in uci)
{
    df = getDataBase(database = database)
    res = rbind(res, data.frame(database=database, count=length(df$Y)))
}
res
```

Résultat de la simulation : 
---------------------------
                   model      database   eta      error
1             perceptron breast.cancer 1e-01 0.02631579
2             perceptron    ionosphere 1e-02 0.10625000
3             perceptron      spambase 1e-03 0.35838401
4                adaline breast.cancer 1e-01 0.02076023
5                adaline    ionosphere 1e-03 0.03920455
6                adaline      spambase 1e-01 0.24022589
7  regression_logistique breast.cancer 1e-04 0.03222222
8  regression_logistique    ionosphere 1e-05 0.04943182
9  regression_logistique      spambase 1e-04 0.38335360
10         Adaboost_prof breast.cancer 1e-02 0.01023392
11         Adaboost_prof    ionosphere 1e-02 0.02102273
12         Adaboost_prof      spambase 1e-04 0.10955691

```{r}
# Graphe a générer
library("ggplot2")
data <- read.table(paste(".", "result", sep = "/"), sep = " ", header = TRUE)
ggplot(data, aes(model, error, fill=model)) + geom_bar(stat = "identity") + facet_grid(. ~ database) + geom_point(aes(y=eta), size=2, color="red", )
```